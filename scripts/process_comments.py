"""ChatGPT Batch Processing Script"""

import glob
import json
import os
from pydantic import BaseModel

from openai import OpenAI
from tqdm import tqdm

from environ.constants import DATA_PATH, PROCESSED_DATA_PATH

client = OpenAI(api_key=os.getenv("OPENAI_API"))


# # Load comments from JSONL files
# comments_path = glob.glob(f"{DATA_PATH}/solana/raydium/reply/*.jsonl")

# comments = {}
# counter = 0
# for file_path in comments_path:
#     with open(file_path, "r", encoding="utf-8") as file:
#         for line in file:
#             counter += 1
#             comment = json.loads(line.strip())
#             comments[counter] = {
#                 "id": comment["id"],
#                 "comment": comment,
#                 "token_add": file_path.split("/")[-1].split(".")[0],
#             }

# with open(PROCESSED_DATA_PATH / "comments.json", "w", encoding="utf-8") as f:
#     json.dump(comments, f, indent=4)

# Few-shot Learning
SYSTEM_INSTRUCTION = (
    "You are a meme coin comment analyzer. "
    "I will provide a comment related to a meme coin. Your task is to determine whether the comment is likely generated by a bot. "
    "Bot-generated comments are often short, context-less, and mass-producible slogans that express hype or hostility. "
    "In contrast, human-generated comments tend to be more personalized and nuanced, containing context or opinion with reasoning. "
    "Comments that reference other users (e.g., #89009679) are typically human-generated, although not all human comments contain such references. "
    "id refers to the number before the sentence. "
    "Respond with id and true (if the comment is bot-generated) or false (if it is human-generated). "
    "Your response should follow this format: "
    '{"id": <id>, "bot": <true/false>}. '
)

TRUE_EXAMPLE = [
    "ill pay for dex",
    "let the jeeters go and next stop the fuckin moon",
    "send it to the moon",
    "TO THE MOON!!! READYY",
    "Go on jeet now! We want no paper hands. The community is holding strong and we'll get there! LFG",
    "this is going to send",
    "Dev is selling",
    "Worst token",
    "Run",
    "I will send 5 sol to the one who CTO",
]

FALSE_EXAMPLE = [
    "#89009679 Lmao WATCH THIS RISES TO MEGA MILLIONS",
    "Mfker is pumping crazy after I sold",
    "#89089152 Stop spamming",
    "that guy is so dumb. he barely got any money. he would have made more from the coin going up.",
    "#89016342 what in the actual fuck is this atrocity?",
    "scam mfq I invested 8 BUCKS MF I'm not stupid u won't be rich by my 4 USD thejacket MF",
    "#88857219 show screenshot as proof pls?",
    "goes to ray and goes crazy for a bit then grows steady just hold and chill",
    "Fake web bros, not same ca",
    "Obvious scam but derivatives of trump coin should go up as people who missed the boat buy into the hype",
]

FEW_SHOT_EXAMPLES = []
FEW_SHOT_EXAMPLES += [
    item
    for idx, comment in enumerate(TRUE_EXAMPLE, 1)
    for item in (
        {"role": "user", "content": f"{idx} {comment}"},
        {"role": "assistant", "content": '{"id": ' + str(idx) + ', "bot": true}'},
    )
]
FEW_SHOT_EXAMPLES += [
    item
    for idx, comment in enumerate(FALSE_EXAMPLE, len(TRUE_EXAMPLE) + 1)
    for item in (
        {"role": "user", "content": f"{idx} {comment}"},
        {"role": "assistant", "content": '{"id": ' + str(idx) + ', "bot": false}'},
    )
]

JSON_SCHEMA = {
    "name": "meme_coin_comment_analyzer",
    "schema": {
        "type": "object",
        "properties": {
            "id": {
                "type": "integer",
                "description": "The unique identifier for the comment.",
            },
            "bot": {
                "type": "boolean",
                "description": "Indicates whether the comment is generated by a bot (true) or human-generated (false).",
            },
        },
        "required": ["id", "bot"],
        "additionalProperties": False,
    },
    "strict": True,
}


with open(PROCESSED_DATA_PATH / "comments.json", "r", encoding="utf-8") as f:
    comments = json.load(f)

with open(f"{PROCESSED_DATA_PATH}/comments_batch.jsonl", "w", encoding="utf-8") as out_f:
    for idx, comment in tqdm(
        comments.items(),
        desc="Preparing batch inputs",
        total=len(comments),
        leave=False,
    ):
        user_msg = f"{idx} {comment['comment']['text']}"
        request_payload = {
            "custom_id": idx,
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": {
                "model": "gpt-4o-mini",
                "messages": [
                    {"role": "system", "content": SYSTEM_INSTRUCTION},
                    *FEW_SHOT_EXAMPLES,
                    {"role": "user", "content": user_msg},
                ],
                "max_tokens": 1000,
                "response_format": {
                    "type": "json_schema",
                    "json_schema": JSON_SCHEMA,
                },
                "temperature": 0,
            },
        }
        out_f.write(json.dumps(request_payload, ensure_ascii=False) + "\n")

batch_input_file = client.files.create(
    file=open(f"{PROCESSED_DATA_PATH}/comments_batch.jsonl", "rb"),
    purpose="batch"
)

batch_input_file_id = batch_input_file.id
client.batches.create(
    input_file_id=batch_input_file_id,
    endpoint="/v1/chat/completions",
    completion_window="24h",
    metadata={
        "description": "meme comment bot detection"
    }
)
    # response = client.chat.completions.create(
    #     model="gpt-4o-mini",
        # messages=[
        #     {"role": "system", "content": SYSTEM_INSTRUCTION},
        #     *FEW_SHOT_EXAMPLES,
        #     {
        #         "role": "user",
        #         "content": f"{idx} {comment['comment']['text']}",
        #     },
        # ],
    #     temperature=0,
    #     response_format={
    #         "type": "json_schema",
    #         "json_schema": JSON_SCHEMA,
    #     },
    # )
    # result_text = response.choices[0].message.content
    # print([idx, comment["comment"]["text"], json.loads(result_text)])
    # break
